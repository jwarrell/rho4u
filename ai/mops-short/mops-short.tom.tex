\section{Consciousness as the colonization of the brain}

\href{https://en.wikipedia.org/wiki/Joscha_Bach}{\uline{\textcolor[HTML]{1155CC}{Joscha Bach}}} recently argued that mobile concurrency is at odds with \href{https://en.wikipedia.org/wiki/Artificial_general_intelligence}{\uline{\textcolor[HTML]{1155CC}{artificial general intelligence}}}.\footnote{In private conversation.} Joscha’s argument is that brains are only plastic, i.e. the connections between neurons are only changing during learning, but not during general computation. Here we argue that this position assumes that the mind is not hosted in a logical model of computation that runs on the brain’s hardware. After all, the \href{https://en.wikipedia.org/wiki/Java_virtual_machine}{\uline{\textcolor[HTML]{1155CC}{Java virtual machine}}} (JVM) is a very different model of computation than the hardware it runs on. \href{https://en.wikipedia.org/wiki/Haskell}{\uline{\textcolor[HTML]{1155CC}{Haskell}}}’s model of computation is an even more dramatic variation on the idea of computation than the one embodied in the hardware the glorious Haskell compiler (\href{https://en.wikipedia.org/wiki/GHC}{\uline{\textcolor[HTML]{1155CC}{GHC}}}) is typically hosted on. Why wouldn’t the mind be organized like this? To use Joscha’s graphic metaphor, why wouldn’t the mind arise as a colonizing computational model that hosts itself on the brain’s hardware. 

\vspace{1\baselineskip}
In particular, we present a model of multi-agent systems, the \href{https://www.sciencedirect.com/science/article/pii/S1571066105051893}{\uline{\textcolor[HTML]{1155CC}{rho-calculus}}}, that does provide direct support for mobile concurrent computation. The communication topology amongst a society of processes executing in the rho-calculus is dynamic. Who knows whom and can talk to whom in this society changes over the course of the computation. This way of thinking about the rho-calculus foreshadows the argument presented here that there are very good reasons to suppose that a model like the rho-calculus may have hosted itself on and colonized the hardware of the human brain, in fact any brain that supports a theory of mind. 

\vspace{1\baselineskip}
\section{Code, data, and computation}

To make this argument i want to make some distinctions that not every computer scientist, let alone every developer makes. i make a distinction between code, data, and computation. Arbitrary code can be treated as some data which is an instance of some type of data structure in which the model of computation is expressed, or hosted. For example, you can host a \href{https://en.wikipedia.org/wiki/Turing_completeness}{\uline{\textcolor[HTML]{1155CC}{Turing-complete computational model}}}, like Haskell, in a term language expressed via a \href{https://en.wikipedia.org/wiki/Context-free_grammar}{\uline{\textcolor[HTML]{1155CC}{context-free grammar}}}, e.g. the grammar for well formed Haskell programs. Yet, we know that context-free grammars are not Turing-complete. How can this be? How can something provably less expressive than Turing-complete models represent Turing-complete computation?

\vspace{1\baselineskip}
It cuts to the heart of the distinction between syntax and semantics. The grammar of the term language expresses the \textit{syntax} of programs, not the \textit{dynamics of computation}, i.e, the semantics of code. Instead, the dynamics of computation arise by the interaction of rules (that operate on the syntax) with a particular piece of syntax, i.e. some code, representing the computation one wants to effect. In the lambda calculus (the model of computation on which Haskell is based) the workhorse of computation is a rule called beta reduction. This rule represents the operation of a function on data through the act of substituting the data for variables occurring in code. The data it operates on is a syntactic representation of the application of a function to data, but it is not the computation that corresponds to \textit{applying the function to the data}. That computation happens when beta reduction operates on the syntax, transforming it to a new piece of syntax. This distinction is how models that are less expressive than Turing-complete (e.g. context-free grammars) can host Turing-complete computation. 

\vspace{1\baselineskip}
Not to belabor the point, but the same distinction happens in Java and JVM. The dynamics of computation in the JVM happen through rules that operate on a combination of registers in the virtual machine together with a representation of the code. A Java programmer staring at a piece of Java code is not looking at the computation. Far from it. The syntax of a Java program is a window into a whole range of possibly different computations that come about depending on the state of the registers of the JVM at the time the code is run. The difference between these two forms of evaluation, beta reduction in the lambda calculus versus the transitions of the JVM is very important and we will return to it.

\vspace{1\baselineskip}
For now, though, one way to think about this distinction between code and computation is through an analogy with physics. Traditionally, the laws of physics are expressed through three things: a representation of physical states (think of this as the syntax of programs); laws of motion that say how states change over time (think of this as the rules that operate on syntax); and initial conditions (think of this as a particular piece of code you want to run). In this light, physics is seen as a special purpose programming language whose execution corresponds in a particular fashion to the way the physical world evolves, based on our observations of it. Physics is \textit{testable} because it lets us run a program and see if the evolution of some initial state to a state it reaches via the laws of motion matches our observations. In particular, when we see the physical world in a configuration that matches our initial state, does it go through a process of evolution that matches what our laws of motion say it should and does it land in a state that our laws of motion say it should. The fact that physics has this shape is why we can represent it effectively in code.

\vspace{1\baselineskip}
Once we see the distinction between code and computation, then the distinction between code and data is relatively intuitive, though somewhat subtle. Data in a computer program is also just syntax. In this sense it is no different than code, which is also just syntax. Every Lisp programmer understands this idea that somehow code is data and data is code. Even Java supports a kind of metaprogramming in which Java code can be manipulated as Java objects. The question is, is there any real dividing line between code and data? 

\vspace{1\baselineskip}
The answer is a definitive yes. Data is code that has very specific properties, for example the code always provably runs to termination. Not all code does this. In fact, Turing’s famous resolution of the \href{https://en.wikipedia.org/wiki/Entscheidungsproblem}{\uline{\textcolor[HTML]{1155CC}{Entscheidungsproblem}}} shows us that we cannot, in general, know when a program will halt for a language enjoying a certain quality of expressiveness, i.e Turing-completeness. But, there are less expressive languages, and Turing-complete languages enjoy suitable sublanguages or fragments that are less expressive than the whole language. Data resides in syntax that allows proving that the computation associated with a piece of syntax will halt. Likewise, data resides in syntax that allows proving that the computation will only enjoy finite branching. 

\vspace{1\baselineskip}
Programmers don’t think about data like this, they just know data when they see it. But in models of computation like the lambda calculus that doesn’t come equipped with built in data types, everything, even things like the counting numbers or the Boolean values true and false are represented as code. Picking out which code constitutes data and which constitutes general purpose programs has to do with being able to detect when code has the sorts of properties we discussed above. In general, there are type systems that can detect properties like this. Again, it’s a subtle issue, but fortunately we don’t need to understand all the subtleties, nor do we need to understand exactly where the dividing line between data and code is, just that there is one. 

\vspace{1\baselineskip}
In summary code and data are both just syntax that represents a state upon which a rule, or many rules, will operate. Data is expressed in a less expressive fragment of the syntax than code, giving it a definite or finitary character that code doesn’t always enjoy. Computation is the process of evolution arising when some rules interact with a representation of a state. Now, what does all this have to do with AI or the mind or even the rho-calculus?

\vspace{1\baselineskip}
\section{Reflection as a defining characteristic of intelligence}

The rho-calculus has a syntactic representation of the distinction between computation and code. It has an operation that expresses packaging up a computation as a piece of code so that it can be operated on, transforming it into new code. It also has an operation for turning a piece of code back into a computation. Whoah, you might say, that is some next level sh!t. But, as we mentioned Lisp programmers, and Java programmers have been doing this sort of metaprogramming for a long time. They have to. The reason has to do with scale. It is impossible for human teams to manage codebases involving millions and millions of lines of code without automated support. They use computer programs to write computer programs. They use computer programs to build computer program deployments. Metaprogramming is a necessity in today’s world.

\vspace{1\baselineskip}
But way back in the ‘80’s, still the early days of AI, a researcher named \href{https://en.wikipedia.org/wiki/Brian_Cantwell_Smith#:~:text=Brian\%20Cantwell\%20Smith\%20is\%20a,\%2C\%20and\%20philosophy\%2C\%20especially\%20ontology.}{\uline{\textcolor[HTML]{1155CC}{Brian Cantwell Smith}}} made an observation that resonated with me and many other people in AI and AI-adjacent fields. Smith’s argument is that introspection, the ability for the mind to look at the mind’s own process, is a key feature of intelligence. For some this is even the defining feature of intelligence. To make this idea of introspection, which he called computational reflection, concrete, Smith designed \href{https://www.ics.uci.edu/~jajones/INF102-S18/readings/17_Smith84.pdf}{\uline{\textcolor[HTML]{1155CC}{a language called 3-Lisp}}} that has the same operators that the rho-calculus has. Specifically, 3-Lisp has syntax to represent reifying a computation into code, and syntax for reflecting code back into running computation.

\vspace{1\baselineskip}
Now, there is a good reason to suspect that there is a connection between the problem of scale that today’s developers face and the problem of modeling our reflective, introspective capacity as reasoning beings. In particular, managing the complexity of representing our own reasoning becomes tractable in the presence of computational reflection. We can apply all of our algorithmic tricks to representations of our own reasoning to obtain better reasoning. This observation is amplified in the context of what evolutionary biologists and psychologists call \href{https://en.wikipedia.org/wiki/Theory_of_mind}{\uline{\textcolor[HTML]{1155CC}{theory of mind}}}. 

\vspace{1\baselineskip}
Specifically, introspection arises from the evolutionary advantage gained by being able to computationally model the behaviors of others, in particular members of your own species. If Alice develops the ability to model Barbara’s behavior, and Barbara is remarkably similar to Alice (as in same species, same tribe, even same extended family structure), then Alice is very close to being able to model Alice’s behavior. And when Alice needs to model Barbara’s behavior when Barbara is interacting with Alice, then Alice is directly involved in modeling Alice’s behavior. Taking this up to a scale where Alice can model her family unit, or the behavior of her tribe is where things get really interesting. More on that shortly, but for now we can see that something about computational reflection has to do with improving reasoning at scale in two senses of that word: (the complexity scale) improving reasoning by applying reasoning to itself; and (the social scale) improving reasoning about large numbers of reasoning agents.

\vspace{1\baselineskip}
In fact, Smith’s ideas about computational reflection and its role in intelligence and the design of programming languages were an inspiration for the design of the rho-calculus, which takes reification and reflection as primitive computational operators. However, where 3-Lisp and the rho-calculus part company is that 3-Lisp is decidedly sequential. It has no way to reasonably represent a society of autonomous computational processes running independently while interacting and coordinating. But in the context of a theory of mind this is just what a reasoner needs to do. They need an explicit model of their social context, which is made up of autonomous agents acting independently while also communicating and coordinating.
