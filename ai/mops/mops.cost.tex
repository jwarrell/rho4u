\section{The cost of transitions}
\subsection{Network access tokens}
If you’re reading this, chances are that you know what an Internet-facing API is, and why it might need to be protected from denial of service attacks. But, just in case you’re one of the “normies”  that don’t know what these terms refer to, let’s you, me, Sherman, and Mr. Peabody all take a trip in the WayBack Machine way back to 2005. 

In those days there was still a naivete about the infinite potential of free and open information. QAnon, deep fakes, ChatGPT and other intimations that the Internet might just be the modern equivalent of the Tower of Babel were not yet even a gleam in their inventors’ eyes. Companies would regularly set up network services that anyone with an Internet connection could access, from anywhere in the world (dubbed Internet-facing). Such services were accessed by sending requests in a particular, well defined format (deriving from the software term application program interface, or API) to an Internet address served by machines in the network service the organization had set up. 

It was quickly discovered that such Internet-facing APIs were vulnerable to attack. If a single bad actor sent thousands or millions of requests to the service, or a botnet of millions sent a few requests each to the service, it was possible for the service to become bogged down and unresponsive to legitimate requests. Now, in reality, all this was discovered long before 2005. But, by 2005 a practice for dealing with this kind of attack was more or less well established. 

The solution is simple. The network proprietor issues a digital token. A request with a given token embedded in it is honored, up to some number of requests per token. This practice is less onerous and costly than having to issue and maintain authorization credentials for login challenges. Many, many companies do this and have done this for the better part of two decades. Not just software or digital service companies like Google and Microsoft issue tokens like this,  Other companies, such as media companies like The New York Times, and The Guardian, also employ this practice. (The hyperlinks above are to their token distribution pages.) The practice is ubiquitous and well accepted. It is intrinsic to the functionality of an open network such as the Web.


Also, it is important to note that many of these services allow for storage of digital content on the networks provided by these services. However, bad actors can still abuse the services by repeatedly uploading illegal content (like child pornography, copyrighted material or even nuclear secrets). So, an entity offering Internet-enabled services must reserve the right to invalidate these tokens in case they discover they are being abused in this or other ways. These utility tokens are essential to comply with a whole host of very good laws.

\subsection{Ethereum’s big idea}
Satoshi’s discovery of a new class of economically secured, leaderless distributed consensus protocols, embodied in proof-of-work but also, elsewhere, embodied in proof-of-stake and other consensus algorithms, was a pretty good idea. It led to the Bitcoin network. Buterin’s suggestion that Satoshi’s consensus be applied to the state of a virtual machine instead of a ledger was a really good idea, and led to the Ethereum network. It creates a distributed computer that runs everywhere and nowhere in particular. Less poetically, every node in the network is running a copy of the virtual machine and the consensus protocol ensures that all the copies agree on the state of the virtual machine.

Like the Internet-facing APIs launched all throughout the 00’s and beyond, Ethereum’s distributed computer is accessible to anyone with an Internet connection. And, as such, without protection would be vulnerable to denial of service  attacks. In fact, it’s potentially even more vulnerable because a request to the Ethereum distributed computer is a piece of code. This code could, in principle, run forever, or take up infinite storage space. Vitalik’s clever idea, building on the established practice of network access tokens, is to require tokens for each computational or storage step to prevent such abuses.

\subsection{MeTTa effort objects}
MeTTa takes the same approach. Transitions in the operational semantics cost a computational resource (effort objects, or EOs, for short) that are ``purchased'' with tokens. This section reprises the operational semantics with the cost of each step spelled out in terms of the structure of EOs.

\subsubsection{Resource-bounded Rewrite Rules}

We assume a polymorphic cost function $\mathsf{\#}$ taking values in the domain of EOs. We assume the domain of EOs supports a notion of $+$ making it a \emph{commutative} monoid.

\begin{mathpar}
  \inferrule* [lab=Query]{\sigma_{i} = \mathsf{unify}(t',t_{i}), k = \mathsf{\{} (\mathsf{=}\; t_{1} \; u_{1}), \ldots, (\mathsf{=}\; t_{n} \; u_{n}) \mathsf{\}} \pplus k', \mathsf{insensitive}(t',k')}{\langle \mathsf{\{} t' \mathsf{\}} \pplus i, k, w, o \rangle \xrightarrow{\Sigma_{i}\mathsf{\#}(\sigma_{i}) + \Sigma_{i}\mathsf{\#}(u_{i}\sigma_{i})} \langle i, k, \mathsf{\{} u_{1}\sigma_{1} \mathsf{\}} \pplus\; \ldots\; \pplus \mathsf{\{} u_{n}\sigma_{n} \mathsf{\}} \pplus w, o \rangle} \\
  \and
  \inferrule* [lab=Chain]{\sigma_{i} = \mathsf{unify}(u,t_{i}), k = \mathsf{\{} (\mathsf{=}\; t_{1} \; u_{1}), \ldots, (\mathsf{=}\; t_{n} \; u_{n}) \mathsf{\}} \pplus k', \mathsf{insensitive}(u,k')}{\langle i, k, \mathsf{\{} u \mathsf{\}} \pplus w, o \rangle \xrightarrow{\Sigma_{i}\mathsf{\#}(\sigma_{i}) + \Sigma_{i}\mathsf{\#}(u_{i}\sigma_{i})} \langle i, k, \mathsf{\{} u_{1}\sigma_{1} \mathsf{\}} \pplus\; \ldots\; \pplus \mathsf{\{} u_{n}\sigma_{n} \mathsf{\}} \pplus w, o \rangle} \\
  \and
  \inferrule* [lab=Transform]{\sigma_{i} = \mathsf{unify}(t,t_{i}), k = \mathsf{\{} t_{1}, \ldots, t_{n} \mathsf{\}} \pplus k',\mathsf{insensitive}(t,k') }{\langle \mathsf{\{} \mathsf{(}\mathsf{transform}\; t \; u\mathsf{)} \mathsf{\}} \pplus i, k, w, o \rangle \xrightarrow{\Sigma_{i}\mathsf{\#}(\sigma_{i}) + \Sigma_{i}\mathsf{\#}(u\sigma_{i})} \langle i, k, \mathsf{\{} u\sigma_{1} \mathsf{\}} \pplus\; \ldots\; \pplus \mathsf{\{} u\sigma_{n} \mathsf{\}} \pplus w, o \rangle} \\
  \and
  \inferrule* [lab=AddAtom1]{}{\langle \mathsf{\{} \mathsf{(} \mathsf{addAtom}\; t\mathsf{)}\mathsf{\}}  \pplus i, k, o \rangle \xrightarrow{\mathsf{\#}(t)} \langle i, k \pplus \mathsf{\{} t\mathsf{\}}, w, \mathsf{\{} \mathsf{()}\mathsf{\}} \pplus o \rangle} \\
  \and
  \inferrule* [lab=AddAtom2]{\langle i_{1}, k_{1}, w_{1}, o_{1}\rangle \xrightarrow{c} \langle i_{2}, k_{2}, w_{2}, o_{2} \rangle, k_{3} = \mathsf{\{} \mathsf{(} \mathsf{addAtom}\; t\mathsf{)}\mathsf{\}} \pplus k_{1}}{\langle i_{1}, k_{3}, w_{1}, o_{1}\rangle \xrightarrow{\mathsf{\#}(t)} \langle i_{2}, \mathsf{\{} \mathsf{(} \mathsf{addAtom}\; t\mathsf{)}, t\mathsf{\}} \pplus k_{2}, w_{2}, \mathsf{\{} \mathsf{()}\mathsf{\}} \pplus o_{2} \rangle} \\
  \inferrule* [lab=RemAtom1]{}{\langle \mathsf{\{} \mathsf{(} \mathsf{remAtom}\; t\mathsf{)}\mathsf{\}}  \pplus i, \mathsf{\{} t \mathsf{\}} \pplus k, w, o \rangle \xrightarrow{\mathsf{\#}(t)} \langle i, k,  \mathsf{\{} w, \mathsf{()}\mathsf{\}} \pplus o \rangle} \\
  \and
  \inferrule* [lab=RemAtom2]{\langle i_{1}, k_{1}, w_{1}, o_{1}\rangle \xrightarrow{c} \langle i_{2}, k_{2}, w_{2}, o_{2} \rangle, k_{3} = \mathsf{\{} \mathsf{(} \mathsf{remAtom}\; t\mathsf{)} \mathsf{\}} \pplus \mathsf{\{} t \mathsf{\}} \pplus k_{1}}{\langle i_{1}, k_{3}, w_{1}, o_{1}\rangle \xrightarrow{\mathsf{\#}(t)} \langle i_{2}, \mathsf{\{} \mathsf{(} \mathsf{remAtom}\; t\mathsf{)}\mathsf{\}} \pplus k_{2}, w_{2}, \mathsf{\{} \mathsf{()}\mathsf{\}} \pplus o_{2} \rangle} \\
  \and
  \inferrule* [lab=Output]{\mathsf{insensitive}(u,k)}{\langle i, k, \mathsf{\{} u \mathsf{\}} \pplus w, o \rangle \xrightarrow{\mathsf{\#}(u)} \langle i, k, w, \mathsf{\{} u \mathsf{\}} \pplus o \rangle}
\end{mathpar}

