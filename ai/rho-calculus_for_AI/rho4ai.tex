% +------------------------------------+
% |   Generated by www.docx2latex.com  |
% |   Version: 2.0.0                   |
% +------------------------------------+

%\documentclass[10pt]{report}
\documentclass[runningheads]{llncs}

\usepackage {mathpartir}
\usepackage{bigpage}
\usepackage{bcprules}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amstext}
\usepackage{latexsym}
\usepackage{longtable}
\usepackage{stmaryrd}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[normalem]{ulem}
\usepackage[svgnames]{xcolor}
\usepackage[paperheight=27.94cm,paperwidth=21.59cm,left=2.54cm,right=2.54cm,top=2.54cm,bottom=2.54cm]{geometry}
\usepackage[hidelinks]{hyperref}


\setlength\parindent{0pt}
\renewcommand{\arraystretch}{1.3}
\include{rho4ai.local} 

\begin{document}
\input{rho4ai.front}

\section{Multi-agent System and AI}
Multi-agent systems are at least as old as AI, and have enjoyed active
research in a number of fields. Among the various research programmes,
concurrency theory has produced one of the most advanced versions of
mult-agent systems. More specifically, the mobile process calculi
formalize a notion of multi-agent systems that is simultaneously a
foundation for computing, in general, and has been used in a wide
range of successful applications. Surprisingly, the AI community has
not adopted these formalisms, despite the fact that they enjoy
features for reasoning about and executing multi-agent specifications
not found in any other framework.

Notable among these features are
\begin{itemize}
  \item an effective notion of equality of ensembles of agents
    (bisimulation) that comes with powerful proof techniques;
  \item a notion of spatial and behavioral types allowing for
    exceptionally powerful and fine-grained classification of the
    structure and behavior of ensembles of agents;
  \item a theorem relating the notion of equality to classification,
    affording a Liskov-style substitution principle saying when an
    agent or ensemble of agents may be substituted in for another such
    without change to the behavior of the overall ensemble in which
    the substitution was effected.
\end{itemize}

We present a formalism for multi-agent systems sporting these features
while also enjoying the kind of computational reflection Brian Smith
argued for in 3-Lisp. This combination of powers allows for agents to
reason effectively about ensembles of agents, that is to build
internal models of the society of minds they observe in their
environment. In fact, we will argue that these features constitute
the smallest formalism necessary to develop a plausible theory of
mind.

\input{rho4ai.process.calculi}

\vspace{1\baselineskip}

\input{rho4ai.tom}

\vspace{1\baselineskip}
\section{The rho-calculus: from 3-Lisp to Society of Mind}

\vspace{1\baselineskip}
Around the same time Smith was developing his ideas of computational reflection \href{https://en.wikipedia.org/wiki/Marvin_Minsky}{\uline{\textcolor[HTML]{1155CC}{Marvin Minsky}}} was developing his famous \href{https://en.wikipedia.org/wiki/Society_of_Mind}{\uline{\textcolor[HTML]{1155CC}{Society of Mind}}} thesis. My take on Minsky’s proposal is that the mind is something like the US Congress, or any other deliberative body. It consists of a bunch of independent agents who are all vying for different resources (such as funding from the tax base). What we think of as a conscious decision is more like the result of a long deliberative process amongst a gaggle of independent, autonomous agents that often goes on well below conscious experience. But, the deliberative process results in a binding vote, and that binding vote is what is experienced as a conscious decision.

\input{rho4ai.rho.presentation}

\vspace{1\baselineskip}
How can this view, which puts most of the computation outside of conscious reasoning, be reconciled with a view of the mind as essentially, indeed definitionally reflective? The rho-calculus was designed with an answer to this question in mind. The rho-calculus says that computational agents come in just six shapes:

\vspace{1\baselineskip}
\begin{itemize}
	\item 0 - the stopped or null agent that does nothing;

	\item for( y <- x )P - the agent that is listening on the channel x waiting for data that it will bind to the variable y before becoming the agent P;

	\item x!( Q ) - the agent that is sending a piece of code/data on the channel x;

	\item P$\vert$Q - the agent that is really the parallel composition of two agents, P and Q, running concurrently, autonomously;

	\item $\ast$x - the agent that is reflecting the code referred to by x back into a running computation

\end{itemize}
\vspace{1\baselineskip}
Notice how three of these constructs use the symbol x. Two of them use x as though it were a channel for communication between agents, and one of them uses x as though it were a reference to a piece of code. The one magic trick that the rho-calculus has up its sleeve is that channels are references to a piece of code. It takes a bit of getting used to, but it comes with time.

\vspace{1\baselineskip}
Armed with just this much information about the rho-calculus we can return to our narrative about Alice and find parsimonious representations of all of the challenges facing her developing social and introspective intelligence. As outside observers of Alice’s social context we can write down its behavior as a parallel composition of the behavior of each individual. In symbols that’s P1 $\vert$ P2 $\vert$ $\ldots$ $\vert$ Pn where Pi is the model of the ith individual in Alice’s social context. Now, a model of Alice’s behavior needs a representation of that parallel composition for her own behavior to represent reasoning about it. In symbols that’s @( P1 $\vert$ P2 $\vert$ $\ldots$ $\vert$ Pn ). For Alice to have this data located somewhere she has access to it she puts the model on a channel x!( P1 $\vert$ P2 $\vert$ $\ldots$ $\vert$ Pn ), and when she needs to retrieve it she executes

\vspace{1\baselineskip}
for( y <- x )AliceThinkingAboutHerColleagues( y ) $\vert$ x!( P1 $\vert$ P2 $\vert$ $\ldots$ $\vert$ Pn )

\vspace{1\baselineskip}
The workhorse rule of computation in the rho-calculus, which is very similar in spirit to the lambda calculus’ beta reduction, is that an expression like this evolves to

\vspace{1\baselineskip}
AliceThinkingAboutHerColleagues( @( P1 $\vert$ P2 $\vert$ $\ldots$ $\vert$ Pn ) )

\vspace{1\baselineskip}
So, now Alice’s thoughts about her colleagues have an explicit representation of their behavior available to Alice. With it, she can simulate her colleagues behavior by simulating the behavior of P1 $\vert$ P2 $\vert$ ... $\vert$ Pn through operations on @( P1 $\vert$ P2 $\vert$ ... $\vert$ Pn ). We can model Alice observing her colleague’s actual behavior with an expression like Alice $\vert$ P1 $\vert$ P2 $\vert$ ... $\vert$ Pn. Alice can compare her simulation with her observations. In fact, whatever we can model is also available to Alice both to run as well as to reify into data and compare the code and her simulations of it to what she observes of the actual behavior of her social context. This includes Alice’s own behavior. 

\vspace{1\baselineskip}
This may have gone by a little fast, but think about it. This is the smallest set of operations needed for Alice to simultaneously model her social context and herself in it. In particular, threads are ‘consciously available’ to Alice just when her own behavior reifies those threads into data and her processing interacts with that data. This argument is part of what went into the design deliberations for the rho-calculus. It is the smallest model of computation that reconciles Smith’s arguments for computational reflection with Minsky’s arguments for a Society of Mind that fits with evolutionary biology’s account of organisms with a theory of mind. Anything smaller misses a key component of the situation.

\vspace{1\baselineskip}
\section{We have seen the enemy and we are they}

This argument is why it is plausible for a model of computation like the rho-calculus to find purchase on the hardware in Alice’s brain. She needs all the elements of this model to compete with other members of her species who are likewise racing to model the behavior of their social context. This is why, very much to the contrary of Joscha’s position, i would argue that mobile concurrency is at the heart of artificial general intelligence.

\bibliographystyle{plain}   
\bibliography{rho4ai.bib}

\end{document}
